{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using SG with Stable Diffusion v1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stable_diffusion.pipeline_sd import StableDiffusionSGPAGPipeline\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "pipe = StableDiffusionSGPAGPipeline.from_pretrained(\n",
    "    \"/storage/qiguojunLab/litiancheng/models/stable-diffusion-v1-4\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config) # ODE Solvers are better for SG-prev\n",
    "\n",
    "device=\"cuda\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompts = [\"a photograph of an astronaut riding a horse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with no guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=0,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + PAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0.3,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + PAG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0.3,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\",\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + PAG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0.3,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using SG with Stable Diffusion 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stable_diffusion_3.pipeline_sd_3 import StableDiffusion3SGPAGPipeline\n",
    "pipe = StableDiffusion3SGPAGPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3-medium\",\n",
    "    torch_dtype=torch.float16,\n",
    "    pag_applied_layers=[\"blocks.13\"]\n",
    ")\n",
    "\n",
    "device=\"cuda\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompts = [\"a photograph of an astronaut riding a horse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with no guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=0,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + PAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0.7,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + PAG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0.7,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\"\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + PAG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=7.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using SG with Stable Diffusion 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.stable_diffusion_3.pipeline_sd_3 import StableDiffusion3SGPAGPipeline\n",
    "pipe = StableDiffusion3SGPAGPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3.5-large\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "device=\"cuda\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompts = [\"a photograph of an astronaut riding a horse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with no guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=0,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\",\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=3.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\",\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=3.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\",\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=3.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using SG with Flux.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.flux.pipeline_flux import FluxSGPipeline\n",
    "pipe = FluxSGPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "device=\"cuda\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompts = [\"a photograph of an astronaut riding a horse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=3.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\",\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=3.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\",\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=28,\n",
    "    generator=torch.manual_seed(0),\n",
    "    guidance_scale=3.5,\n",
    "    pag_scale=0,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").images[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using SG with CogVideoX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Custom Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cogvideox.pipeline_cogvideox import CogVideoXSGPipeline\n",
    "pipe = CogVideoXSGPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-5b\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "device=\"cuda\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompts = [\"A panda sits on a wooden stool in a serene bamboo forest.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=720,\n",
    "    height=480,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=6,\n",
    "    self_guidance_scale=0,\n",
    "    self_guidance_shift_t=0,\n",
    "    self_guidance_type=\"sg\"\n",
    ").frames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=720,\n",
    "    height=480,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=6,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg\"\n",
    ").frames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling with CFG + SG-prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompts,\n",
    "    width=720,\n",
    "    height=480,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=6,\n",
    "    self_guidance_scale=3,\n",
    "    self_guidance_shift_t=10,\n",
    "    self_guidance_type=\"sg_prev\",\n",
    "    sg_prev_max_t=500\n",
    ").frames[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch251",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
